{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e4adad",
   "metadata": {},
   "source": [
    "## This is a solution for Predict the Correct Grouping of Unevenly Spaced Items\n",
    "We can use a Name Entity Recognition (NER) model to solve this problem. Named-entity recognition (NER) is a subtask of information extraction, that is used to identify and group tokens into a predefined set of named entities.\n",
    "\n",
    "Here is an example of a sentence tagged using IOB tags\n",
    "\n",
    "![img](https://miro.medium.com/v2/resize:fit:982/format:webp/1*iMV2d1OygbT6F8fX0c5YNg.png)\n",
    "\n",
    "The IOB format (short for inside, outside, beginning) is a tagging format that is used for tagging tokens in a chunking task such as named-entity recognition. These tags are similar to part-of-speech tags but give us information about the location of the word in the chunk. The IOB Tagging system contain tags of the form:\n",
    "\n",
    "* B-{CHUNK_TYPE} — for the word in the beginning of the chunk\n",
    "* I-{CHUNK_TYPE} — for words inside the chunk\n",
    "* O — for words outside/not part of the chunk\n",
    "\n",
    "In order to use ner model to solve, we need to setup out data in such way we can fit it into the model and create label in IOB schema. Later, we can reconstruct group of each element by grouping consecutive elements\n",
    "\n",
    "For example, given label of each elements [0, B, I, O, B, I, I], we will have 2 group (a, b) and another group (c, d), and ignore all space entity \n",
    "![Imgur](https://i.imgur.com/sgkfW8B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce320c5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e496c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78123ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Locofy_MLE_Challenge_Groupings/Data/retool.json',\n",
       " 'Locofy_MLE_Challenge_Groupings/Data/wego.json',\n",
       " 'Locofy_MLE_Challenge_Groupings/Data/airbnb.json',\n",
       " 'Locofy_MLE_Challenge_Groupings/Data/uber.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('Locofy_MLE_Challenge_Groupings/Data/*.json')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dea16",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "In the given dataset we have 3 kind of information, which will be encoded to correct format and input to LSTM model\n",
    "* size\n",
    "* entity type ('0' -> space otherwise enity isn't space)\n",
    "* direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9fb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "for fname in files:\n",
    "    path = fname\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for elements in data:\n",
    "        X = []\n",
    "        y = ['O']*len(elements['input'])\n",
    "\n",
    "        indices = {}\n",
    "        # encode direction \n",
    "        direction = 0 if elements['direction'] == 'horizontal' else 1\n",
    "\n",
    "        for idx, e in enumerate(elements['input']):\n",
    "            eid = e[0]\n",
    "            \n",
    "            # encode entity type\n",
    "            if eid == '0':\n",
    "                etype = 0\n",
    "            else:\n",
    "                etype = 1\n",
    "                indices[eid] = idx\n",
    "            \n",
    "            # size\n",
    "            sz = e[1]\n",
    "            X.append((etype, sz))\n",
    "\n",
    "        \n",
    "        # label encode\n",
    "        start_index = []\n",
    "        end_index = []\n",
    "        for entity in elements['output']:\n",
    "            if len(entity) > 1:\n",
    "                start_index.append(indices[entity[0]])\n",
    "                end_index.append(indices[entity[-1]])\n",
    "                if ord(entity[0]) >= ord(entity[-1]):\n",
    "                    print(entity[0], entity[-1])\n",
    "                    print('lol')\n",
    "        \n",
    "        # using BIO schema \n",
    "        for start, end in zip(start_index, end_index):\n",
    "            y[start:end+1] = ['B-TAG'] + ['I-TAG']*(end-start)\n",
    "        \n",
    "        X = {'elements': X, 'direction': direction}\n",
    "        Xs.append(X)\n",
    "        ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd4eb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elements': [(1, 36), (1, 24), (0, 15), (1, 24), (1, 0)], 'direction': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de7cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-TAG', 'I-TAG', 'I-TAG', 'O']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76180da9",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Create batch of sample by right padding all sequence to max_length_sequence in list, and clip entity size in range [0, 1023]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af732f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def get_mask(batch_tensor):\n",
    "    mask = batch_tensor.eq(0)\n",
    "    mask = mask.eq(0)\n",
    "    return mask\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    batch = {key: [d[key] for d in batch] for key in batch[0]}\n",
    "    \n",
    "    tag, seq_length = my_collate(batch['tag'])\n",
    "    sz = my_collate(batch['sz'])[0]\n",
    "    label = my_collate(batch['label'])[0]\n",
    "    direction = torch.tensor(batch['direction'])\n",
    "    mask = get_mask(label)\n",
    "    \n",
    "    return tag, sz, seq_length, direction, mask, label\n",
    "\n",
    "def my_collate(batch_tensor):\n",
    "    word_seq_lengths = torch.LongTensor(list(map(len, batch_tensor)))\n",
    "    batch_tensor.sort(key=lambda x: len(x), reverse=True)\n",
    "    tensor_length = torch.tensor([len(sq) for sq in batch_tensor])\n",
    "    batch_tensor = pad_sequence(batch_tensor, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return batch_tensor, tensor_length\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, Xs, ys, aug=False):\n",
    "\n",
    "        self.Xs = Xs\n",
    "        self.ys = ys\n",
    "        self.labels = ['pad', 'O', 'B-TAG', 'I-TAG']\n",
    "        self.label2idx = {v:k for k, v in enumerate(self.labels)}\n",
    "        self.aug = aug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        X = self.Xs[item]['elements']\n",
    "        y = self.ys[item]\n",
    "        \n",
    "        X = torch.tensor(X)\n",
    "        y = torch.tensor([self.label2idx[i] for i in y])\n",
    "        \n",
    "        direction = torch.tensor(self.Xs[item]['direction'])\n",
    "        tag = X[:, 0]\n",
    "        \n",
    "        delta = 1.0\n",
    "        if self.aug and np.random.uniform(0, 1) > 0.8: \n",
    "            delta = np.random.uniform(0.8, 1.2)\n",
    "#         print(delta)\n",
    "        # max size of entity is 1023\n",
    "        sz = (X[:, 1]*delta).int()\n",
    "        sz  = torch.clip(sz, 0, 1023)\n",
    "        \n",
    "        x = torch.random\n",
    "        return {'direction': direction, 'tag': tag, 'sz': sz, 'label': y}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.1)\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train, aug=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=my_collate_fn)\n",
    "\n",
    "test_dataset = MyDataset(X_test, y_test, aug=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b108d0",
   "metadata": {},
   "source": [
    "Dataloader will return **tag, sz, seq_length, direction, mask, label** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e620750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
       "         [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
       "         [0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0]]),\n",
       " tensor([[  8,  12,   8,  10,   8,  10,   8,  10,   8,  10,   8,  10,   8,  10,\n",
       "           32,  23,   8],\n",
       "         [115, 141,   7,  23,   9,  34,   4,  52, 175, 115,  82,   7, 121,  24,\n",
       "           21,   7,   0],\n",
       "         [ 64,  51,  24, 117,  70,  58,   4, 597,  24,  75, 114,   4,  68,  74,\n",
       "           64,   0,   0],\n",
       "         [392, 100,  16,  54,  16,  46,  16,  62,  16,  20,  16,  20,  16,  16,\n",
       "          408,   0,   0]], dtype=torch.int32),\n",
       " tensor([17, 16, 15, 15]),\n",
       " tensor([0, 0, 0, 0]),\n",
       " tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True, False, False]]),\n",
       " tensor([[1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1],\n",
       "         [1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 3, 3, 1, 0],\n",
       "         [1, 1, 1, 2, 3, 3, 3, 1, 1, 2, 3, 3, 3, 3, 1, 0, 0],\n",
       "         [1, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89664d7f",
   "metadata": {},
   "source": [
    "### Create NER model\n",
    "The architecture of ner model is shown in bellow. it contains some components\n",
    "* Entity type embedding\n",
    "* Size embedding\n",
    "* Direction embedding\n",
    "* Directional LSTM\n",
    "* Classifer\n",
    "\n",
    "Entity embedded and size embedded will be concatenated, and fetch into LSTM. Direction embedded will be initialized for initial hidden states. We predict tag of element at each timestep\n",
    "\n",
    "We train using crossentropy loss\n",
    "<img src=\"https://i.imgur.com/2ClkyI7.png\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f13da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "\n",
    "class NamedEntityRecog(nn.Module):\n",
    "    def __init__(self, tag_size, direction_num, max_postion, tag_embed_dim, size_embed_dim, direction_embed_dim, hidden_dim, label_num, dropout=0.1):\n",
    "        super(NamedEntityRecog, self).__init__()\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.tag_embeds = nn.Embedding(tag_size, tag_embed_dim, padding_idx=0)\n",
    "        self.size_embeds = nn.Embedding(max_postion, size_embed_dim, padding_idx=0)\n",
    "        self.direction_embeds = nn.Embedding(direction_num, direction_embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.input_dim = tag_embed_dim + size_embed_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.hidden2tag = nn.Linear(hidden_dim * 2 , label_num)\n",
    "\n",
    "\n",
    "    def forward(self, tag, sz, seq_length, direction, mask, label=None):        \n",
    "        batch_size = tag.size(0)\n",
    "        seq_len = tag.size(1)\n",
    "        \n",
    "        tag_embedding = self.tag_embeds(tag)\n",
    "        sz_embedding = self.size_embeds(sz)\n",
    "        dir_embedding = self.direction_embeds(direction)\n",
    "        word_embeding = torch.cat([tag_embedding, sz_embedding], 2)\n",
    "        \n",
    "        word_represents = self.drop(word_embeding)\n",
    "        \n",
    "        packed_words = pack_padded_sequence(word_represents, seq_length, True)\n",
    "        hidden = dir_embedding[None].expand(2, -1, -1)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(packed_words, (hidden, hidden))\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out)\n",
    "        lstm_out = lstm_out.transpose(0, 1)\n",
    "        feature_out = self.drop(lstm_out)\n",
    "        feature_out = self.hidden2tag(feature_out)\n",
    "        \n",
    "        if label != None:\n",
    "            loss_function = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "\n",
    "            feature_out = feature_out.contiguous().view(batch_size * seq_len, -1)\n",
    "            total_loss = loss_function(feature_out, label.contiguous().view(batch_size * seq_len))\n",
    "\n",
    "            return total_loss\n",
    "        else:\n",
    "            feature_out = feature_out.contiguous().view(batch_size * seq_len, -1)\n",
    "            _, tag_seq = torch.max(feature_out, 1)\n",
    "            tag_seq = tag_seq.view(batch_size, seq_len)\n",
    "            tag_seq = mask.long() * tag_seq\n",
    "            return tag_seq       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba76c2b",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Given predict labels and true labels, we compute precision, recall, f1 per entity by using seqeval lib. \n",
    "\n",
    "Here is an example predicted tags and labels \n",
    " \n",
    "y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    " \n",
    "y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "tag2label = train_dataset.labels\n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    \n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    for batch in dataloader:\n",
    "        tag, sz, seq_length, direction, mask, label = batch\n",
    "\n",
    "        tag_seq = model(tag, sz, seq_length, direction, mask)\n",
    "        for i in range(len(tag)):\n",
    "            gt = [tag2label[tag_idx] for idx, tag_idx in enumerate(label[i]) if mask[i][idx]==True]\n",
    "            pred = [tag2label[tag_idx] for idx, tag_idx in enumerate(tag_seq[i]) if mask[i][idx]==True]\n",
    "\n",
    "            assert len(gt) == len(pred)\n",
    "            gt_list.append(gt)\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "            \n",
    "    metrics = {\n",
    "            \"precision\": precision_score(gt_list, pred_list),\n",
    "            \"recall\": recall_score(gt_list, pred_list),\n",
    "            \"hmean\": f1_score(gt_list, pred_list),\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85424cd",
   "metadata": {},
   "source": [
    "### Train and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71776797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedEntityRecog(\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (tag_embeds): Embedding(2, 16, padding_idx=0)\n",
       "  (size_embeds): Embedding(1024, 8, padding_idx=0)\n",
       "  (direction_embeds): Embedding(2, 32, padding_idx=0)\n",
       "  (lstm): LSTM(24, 32, batch_first=True, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = NamedEntityRecog(\n",
    "    tag_size=2, \n",
    "    direction_num=2,\n",
    "    max_postion=1024, \n",
    "    tag_embed_dim=16, \n",
    "    size_embed_dim=8, \n",
    "    direction_embed_dim=32,\n",
    "    hidden_dim=32, \n",
    "    label_num=4)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3daeef58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.4348958333333333, 'recall': 0.5585284280936454, 'hmean': 0.4890190336749633}\n",
      "{'precision': 0.767515923566879, 'recall': 0.8060200668896321, 'hmean': 0.7862969004893965}\n",
      "{'precision': 0.8557377049180328, 'recall': 0.8729096989966555, 'hmean': 0.8642384105960265}\n",
      "{'precision': 0.8737864077669902, 'recall': 0.903010033444816, 'hmean': 0.888157894736842}\n",
      "{'precision': 0.896774193548387, 'recall': 0.9297658862876255, 'hmean': 0.9129720853858785}\n",
      "{'precision': 0.9120521172638436, 'recall': 0.9364548494983278, 'hmean': 0.9240924092409241}\n",
      "{'precision': 0.9177631578947368, 'recall': 0.9331103678929766, 'hmean': 0.9253731343283582}\n",
      "{'precision': 0.9570957095709571, 'recall': 0.9698996655518395, 'hmean': 0.9634551495016612}\n",
      "{'precision': 0.9601328903654485, 'recall': 0.9665551839464883, 'hmean': 0.9633333333333334}\n",
      "{'precision': 0.9603960396039604, 'recall': 0.9732441471571907, 'hmean': 0.9667774086378738}\n",
      "{'precision': 0.9766666666666667, 'recall': 0.979933110367893, 'hmean': 0.978297161936561}\n",
      "{'precision': 0.9767441860465116, 'recall': 0.9832775919732442, 'hmean': 0.98}\n",
      "{'precision': 0.9702970297029703, 'recall': 0.9832775919732442, 'hmean': 0.9767441860465116}\n",
      "{'precision': 0.9801324503311258, 'recall': 0.9899665551839465, 'hmean': 0.9850249584026622}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.9867109634551495, 'recall': 0.9933110367892977, 'hmean': 0.9900000000000001}\n",
      "{'precision': 0.9768211920529801, 'recall': 0.9866220735785953, 'hmean': 0.9816971713810316}\n",
      "{'precision': 0.9800664451827242, 'recall': 0.9866220735785953, 'hmean': 0.9833333333333333}\n",
      "{'precision': 0.9867109634551495, 'recall': 0.9933110367892977, 'hmean': 0.9900000000000001}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9867109634551495, 'recall': 0.9933110367892977, 'hmean': 0.9900000000000001}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.9933333333333333, 'recall': 0.9966555183946488, 'hmean': 0.9949916527545909}\n",
      "{'precision': 0.9933333333333333, 'recall': 0.9966555183946488, 'hmean': 0.9949916527545909}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "{'precision': 0.9933333333333333, 'recall': 0.9966555183946488, 'hmean': 0.9949916527545909}\n",
      "{'precision': 0.99, 'recall': 0.9933110367892977, 'hmean': 0.9916527545909849}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.9866666666666667, 'recall': 0.9899665551839465, 'hmean': 0.9883138564273791}\n",
      "{'precision': 0.9833887043189369, 'recall': 0.9899665551839465, 'hmean': 0.9866666666666667}\n",
      "{'precision': 0.9899665551839465, 'recall': 0.9899665551839465, 'hmean': 0.9899665551839465}\n",
      "{'precision': 0.9933110367892977, 'recall': 0.9933110367892977, 'hmean': 0.9933110367892977}\n",
      "model save to model.pt and best h1 : 0.9949916527545909\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "best_f1 = 0\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        model.zero_grad()\n",
    "        tag, sz, seq_length, direction, mask, label = batch\n",
    "\n",
    "        loss = model(tag, sz, seq_length, direction, mask, label)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    metrics = evaluate(test_loader, model)\n",
    "    \n",
    "    if metrics['hmean'] > best_f1:\n",
    "        best_f1 = metrics['hmean']\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    print(metrics)\n",
    "    \n",
    "print('model save to model.pt and best h1 : {}'.format(best_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50323c29",
   "metadata": {},
   "source": [
    "f1 measure is high so model performance is very good "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af18766",
   "metadata": {},
   "source": [
    "### Suggested improvement\n",
    "With the current model performance and the current dataset, i think we already solved the problem well, no need to enhance anymore. anw, i still list some suggestions for further improvement \n",
    "* add entity dimension: topleft, width, height\n",
    "* entity image\n",
    "* text inside entity\n",
    "\n",
    "Add image and text into model will increase complexity and slow down inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661d4f1",
   "metadata": {},
   "source": [
    "### Export to onnx for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b92940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 4 WARNING 0 ERROR ========================\n",
      "4 WARNING were not printed due to the log level.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "/home/pbcquoc/anaconda3/lib/python3.9/site-packages/torch/onnx/symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "input_names = ['tag', 'sz', 'seq_length', 'direction', 'mask']\n",
    "output_names = ['output']\n",
    "dummy = tag, sz, seq_length, direction, mask\n",
    "dummy = tuple(e[[0]] for e in dummy)\n",
    "input_shape = {\n",
    "                'tag': {0: 'batch_size', 1:'seq_length'},\n",
    "                'sz': {0: 'batch_size', 1:'seq_length'},\n",
    "                'seq_length': {0: 'batch_size'},\n",
    "                'direction': {0:'batch_size'},\n",
    "                'mask':{0:'batch_size', 1:'seq_length'}\n",
    "              }\n",
    "\n",
    "state_dict = torch.load('model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "torch.onnx.export(model, dummy, 'model.onnx', input_names=input_names, output_names=output_names, \n",
    "                 dynamic_axes={**input_shape,   \n",
    "                                'output' : {0 : 'batch_size', 1:'seq_length'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa6ea5",
   "metadata": {},
   "source": [
    "### Testing my model using API\n",
    "I also provide endpoint for testing my model. \n",
    "Here is an example using curl command\n",
    "```\n",
    "curl --header \"Content-Type: application/json\" --request POST --data '{\"input\": [[\"0\", 64], [\"a\", 51], [\"0\", 24], [\"b\", 117], [\"c\", 70], [\"d\", 58], [\"e\", 4], [\"0\", 597], [\"f\", 24], [\"g\", 75], [\"h\", 114], [\"i\", 4], [\"j\", 68], [\"k\", 74], [\"0\", 64]], \"direction\": \"horizontal\"}' https://api.vocr.vn/predictions/ner\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2072fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"output\": [\r\n",
      "    \"a\",\r\n",
      "    [\r\n",
      "      \"b\",\r\n",
      "      \"c\",\r\n",
      "      \"d\",\r\n",
      "      \"e\"\r\n",
      "    ],\r\n",
      "    \"f\",\r\n",
      "    [\r\n",
      "      \"g\",\r\n",
      "      \"h\",\r\n",
      "      \"i\",\r\n",
      "      \"j\",\r\n",
      "      \"k\"\r\n",
      "    ]\r\n",
      "  ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl --header \"Content-Type: application/json\" --request POST --data '{\"input\": [[\"0\", 64], [\"a\", 51], [\"0\", 24], [\"b\", 117], [\"c\", 70], [\"d\", 58], [\"e\", 4], [\"0\", 597], [\"f\", 24], [\"g\", 75], [\"h\", 114], [\"i\", 4], [\"j\", 68], [\"k\", 74], [\"0\", 64]], \"direction\": \"horizontal\"}' https://api.vocr.vn/predictions/ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40eb0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': ['a', ['b', 'c', 'd', 'e'], 'f', ['g', 'h', 'i', 'j', 'k']]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "def post(x):\n",
    "    data = requests.post('https://api.vocr.vn/predictions/ner', \n",
    "                         json={ 'input':x['input'], 'direction':x['direction']})\n",
    "    return data.json()\n",
    "\n",
    "x = {\"input\": [[\"0\", 64], [\"a\", 51], [\"0\", 24], [\"b\", 117], [\"c\", 70], [\"d\", 58], [\"e\", 4], [\"0\", 597], [\"f\", 24], [\"g\", 75], [\"h\", 114], [\"i\", 4], [\"j\", 68], [\"k\", 74], [\"0\", 64]], \n",
    "     \"direction\": \"horizontal\"}\n",
    "post(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b92c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
